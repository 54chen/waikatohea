@Misc{ref:neto:wikipedia,
author = {www.wikipedia.org},
note = {Date de dernière consultation : xx/xx/xxxx},
}

@article{ChazelleBernard1983BBHA,
	abstract = {An implementation of the bottom-left heuristic for two-dimensional bin-packing is presented. The method requires linear space and quadratic time. The best implementations found so far require cubic time. It is shown that this algorithm is optimal among all those based on the exhaustive strategy and its generality makes it adaptable to other bin-packing heuristics.},
	address = {New York, NY},
	author = {Chazelle, Bernard},
	copyright = {Copyright 2015 Elsevier B.V., All rights reserved.},
	issn = {0018-9340},
	journal = {IEEE transactions on computers},
	keywords = {Algorithmics. Computability. Computer arithmetics ; Applied sciences ; Bin packing ; bottom-left heuristic ; computational geometry ; Computer science; control theory; systems ; Exact sciences and technology ; geometric pattern matching ; operating systems ; operations research ; scheduling ; Theoretical computing},
	language = {eng},
	number = {8},
	pages = {697-707},
	publisher = {Institute of Electrical and Electronics Engineers},
	title = {BOTTOM-LEFT BIN-PACKING HEURISTIC: AN EFFICIENT IMPLEMENTATION},
	volume = {C-32},
	year = {1983}
    }

@online{3Drecons59:online,
author = {Wikipedia},
title = {3D reconstruction},
url = {https://en.wikipedia.org/wiki/3D_reconstruction#:~:text=In%20computer%20vision%20and%20computer,rigid%20or%20spatio%2Dtemporal%20reconstruction.},
month = {11},
year = {2022},
}


@article{CONDOTTA2020105394,
	abstract = {Low-cost depth-cameras have been used in many agricultural applications with reported advantages of low cost, reliability and speed of measurement. However, some problems were also reported and seem to be technology-related, so understanding the limitations of each type of depth camera technology could provide a basis for technology selection and the development of research involving its use. The cameras use one or a combination of two of the three available technologies: structured light, time-of-flight (ToF), and stereoscopy. The objectives were to evaluate these different technologies for depth sensing, including measuring accuracy and repeatability of distance data and measurements at different positions within the image, and cameras usefulness in indoor and outdoor settings. Then, cameras were tested in a swine facility and in a corn field. Five different cameras were used: (1) Microsoft Kinect v.1, (2) Microsoft Kinect v.2, (3) Intel{\textregistered} RealSense{\texttrademark} Depth Camera D435, (4) ZED Stereo Camera (StereoLabs), and (5) CamBoard Pico Flexx (PMD Technologies). Results indicate that there were significant camera to camera differences for ZED Stereo Camera and Kinect v.1 camera (p < 0.05). All cameras showed an increase in the standard deviation as the distance between camera and object increased; however, the Intel RealSense camera had a larger increase. Time-of-flight cameras had the smallest error between different sizes of objects. Time-of-flight cameras had non-readable zones on the corners of the images. The results indicate that the ToF technology is the best to be used for indoor applications and stereoscopy is the best technology for outdoor applications.},
	author = {Isabella C.F.S. Condotta and Tami M. Brown-Brandl and Santosh K. Pitla and John P. Stinn and K{\'e}sia O. Silva-Miranda},
	doi = {https://doi.org/10.1016/j.compag.2020.105394},
	issn = {0168-1699},
	journal = {Computers and Electronics in Agriculture},
	keywords = {Depth image, Time-of-flight, Stereoscopy, Structured light},
	pages = {105394},
	title = {Evaluation of low-cost depth cameras for agricultural applications},
	url = {https://www.sciencedirect.com/science/article/pii/S0168169919325037},
	volume = {173},
	year = {2020},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0168169919325037},
	bdsk-url-2 = {https://doi.org/10.1016/j.compag.2020.105394}}


@article{machines10030183,
abstract = {This review paper presents an overview of depth cameras. Our goal is to describe the features and capabilities of the introduced depth sensors in order to determine their possibilities in robotic applications, focusing on objects that might appear in applications with high accuracy requirements. A series of experiments was conducted, and various depth measuring conditions were examined in order to compare the measurement results of all the depth cameras. Based on the results, all the examined depth sensors were appropriate for applications where obstacle avoidance and robot spatial orientation were required in coexistence with image vision algorithms. In robotic vision applications where high accuracy and precision were obligatory, the ZED depth sensors achieved better measurement results.},
article-number = {183},
author = {Tadic, Vladimir and Toth, Attila and Vizvari, Zoltan and Klincsik, Mihaly and Sari, Zoltan and Sarcevic, Peter and Sarosi, Jozsef and Biro, Istvan},
doi = {10.3390/machines10030183},
issn = {2075-1702},
journal = {Machines},
number = {3},
title = {Perspectives of RealSense and ZED Depth Sensors for Robotic Vision Applications},
url = {https://www.mdpi.com/2075-1702/10/3/183},
volume = {10},
year = {2022},
bdsk-url-1 = {https://www.mdpi.com/2075-1702/10/3/183},
bdsk-url-2 = {https://doi.org/10.3390/machines10030183}}


@online{Open3D–A73:online,
author = {Open3D},
title = {Open3D – A Modern Library for 3D Data Processing},
url = {http://www.open3d.org/},
month = {10},
year = {2022},
}

@online{Stereola45:online,
author = {Stereolabs},
title = {Stereolabs - Capture the World in 3D},
url = {https://www.stereolabs.com/},
month = {},
year = {2023},
}

@online{Whatisth44:online,
author = {Myzhar},
title = {What is the different between 2K and 1080HD? Better depth range? - Software / Python - Stereolabs Community},
url = {https://community.stereolabs.com/t/what-is-the-different-between-2k-and-1080hd-better-depth-range/2019/10},
month = {2},
year = {2023},
}

@online{Howdoest30:online,
author = {ZED},
title = {How does the ZED work? – Help Center | Stereolabs},
url = {https://support.stereolabs.com/hc/en-us/articles/206953039-How-does-the-ZED-work-},
month = {},
year = {},
}

@online{Usingthe89:online,
author = {Stereolabs},
title = {Using the Positional Tracking API | Stereolabs},
url = {https://www.stereolabs.com/docs/positional-tracking/using-tracking/#getting-pose},
month = {},
year = {2021},
}

@online{authorja50:online,
author = {zerocode},
title = {authorjapps/zerocode: A community-developed, free, open source, microservices API automation and load testing framework built using JUnit core runners for Http REST, SOAP, Security, Database, Kafka and much more. Zerocode Open Source enables you to create, change, orchestrate and maintain your automated test cases declaratively with absolute ease.},
url = {https://github.com/authorjapps/zerocode},
month = {},
year = {2023},
}

@online{larize48:online,
author = {},
title = {Polarizer - Wikipedia},
url = {https://en.wikipedia.org/wiki/Polarizer},
month = {},
year = {},
}

@online{Rollings50:online,
author = {},
title = {Rolling shutter - Wikipedia},
url = {https://en.wikipedia.org/wiki/Rolling_shutter},
month = {},
year = {},
}

@online{Exposure66:online,
author = {},
title = {Exposure (photography) - Wikipedia},
url = {https://en.wikipedia.org/wiki/Exposure_(photography)},
month = {},
year = {},
}

@online{ZED2iDat76:online,
author = {},
title = {ZED 2i Datasheet Feb2022},
url = {https://cdn2.stereolabs.com/assets/datasheets/ZED%202i%20Datasheet%20Jan2023.pdf},
month = {},
year = {},
}

@online{ZED2iInd52:online,
author = {},
title = {ZED 2i - Industrial AI Stereo Camera | Stereolabs},
url = {https://www.stereolabs.com/zed-2i/},
month = {},
year = {},
}
 
@online{ZEDSDK3:online,
author = {},
title = {ZED SDK 3.8 - Download | Stereolabs},
url = {https://www.stereolabs.com/developers/release/},
month = {},
year = {},
}

@online{UseAmazo38:online,
author = {},
title = {Use Amazon SageMaker Ground Truth to Label Data - Amazon SageMaker},
url = {https://docs.aws.amazon.com/sagemaker/latest/dg/sms.html},
month = {},
year = {},
}

@online{MLflowAp90:online,
author = {},
title = {MLflow - A platform for the machine learning lifecycle | MLflow},
url = {https://mlflow.org/},
month = {},
year = {},
}

@online{Jenkins2:online,
author = {},
title = {Jenkins},
url = {https://www.jenkins.io/},
month = {},
year = {},
}


@online{AWSCodeP0:online,
author = {},
title = {AWS CodePipeline Features},
url = {https://aws.amazon.com/codepipeline/features/},
month = {},
year = {},
}

@online{MachineL60:online,
author = {},
title = {Machine Learning Engineering for Production (MLOps) | Coursera},
url = {https://www.coursera.org/specializations/machine-learning-engineering-for-production-mlops},
month = {},
year = {},
}

@book{prince2023understanding,
 author = "Simon J.D. Prince",
 title = "Understanding Deep Learning",
 publisher = "MIT Press",
 year = 2023,
 url = "https://udlbook.github.io/udlbook/"
}

@online{20Andrej30:online,
author = {},
title = {(20) Andrej Karpathy - AI for Full-Self Driving at Tesla - YouTube},
url = {https://www.youtube.com/watch?v=hx7BXih7zx8},
month = {},
year = {},
}

@online{authorja66:online,
author = {},
title = {authorjapps/zerocode: A community-developed, free, open source, microservices API automation and load testing framework built using JUnit core runners for Http REST, SOAP, Security, Database, Kafka and much more. Zerocode Open Source enables you to create, change, orchestrate and maintain your automated test cases declaratively with absolute ease.},
url = {https://github.com/authorjapps/zerocode},
month = {},
year = {},
}

@misc{DSpaceIn8:online,
author = {},
title = {DSpace - Institutional repository software - KEEP SOLUTIONS},
howpublished = {\url{https://www.keep.pt/en/produts/dspace-open-source-institutional-repository-software/}},
month = {},
year = {},
note = {(Accessed on 03/29/2023)}
}

@misc{FeatureL22:online,
author = {},
title = {Feature List - Omeka Classic User Manual},
howpublished = {\url{https://omeka.org/classic/docs/GettingStarted/Feature_List/}},
month = {},
year = {},
note = {(Accessed on 03/29/2023)}
}

@misc{Introduc17:online,
author = {},
title = {Introduction — Invenio 3.1.2 documentation},
howpublished = {\url{https://invenio.readthedocs.io/en/maint-3.1/general/introduction.html#a-framework}},
month = {},
year = {},
note = {(Accessed on 03/29/2023)}
}

@misc{WelcomeG98:online,
author = {},
title = {Welcome :: Greenstone Digital Library Software},
howpublished = {\url{https://www.greenstone.org/}},
month = {},
year = {},
note = {(Accessed on 03/29/2023)}
}

@misc{EPrintsS41:online,
author = {},
title = {EPrints Services},
howpublished = {\url{https://www.eprints.org/uk/}},
month = {},
year = {},
note = {(Accessed on 03/29/2023)}
}

@misc{AboutMuk17:online,
author = {},
title = {About - Mukurtu CMS},
howpublished = {\url{https://mukurtu.org/about/}},
month = {},
year = {},
note = {(Accessed on 03/29/2023)}
}

@online{FeatureL61:online,
author = {},
title = {Feature List - Omeka Classic User Manual},
url = {https://omeka.org/classic/docs/GettingStarted/Feature_List/},
month = {},
year = {},
}
